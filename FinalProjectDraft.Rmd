---
title: "STAT0218 Final Project"
author: "Ellie Suit, Andy Atallah, and Ai Hattori"
date: "2023-12-18"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load packages, warning = F, message = F}
# libraries 
library(tidyverse)
library(lubridate) # convert PlantDate to date object
library(dendextend) # hierarchical clustering
library(survival) # survival analysis

# random forest
library(rpart)
library(rpart.plot)
library(ranger)
library(rms) # validate R-part
library(randomForest)

# SVM
library(kernlab)
library(e1071)
library(caret) # test of SVM
library(LiblineaR) # caret SVM testing
library(kernlab) # caret SVM testing
library(survivalsvm) # functional SVM 
library(survminer) # plotting survival curves

# set a seed
set.seed(1)
```

```{r load data, warning = F, message = F}
trees <- read_csv("Tree_Data.csv")
#trees <- read_csv(file.choose())
```

## 1. Ellie, Ai, Andy: Introduction and Motivation 

In this study, we make predictions on the factors that influence tree survival amongst seedlings to determine which aspects contribute the most to tree health. In particular, we analyze the plant-soil relationships to characterize how qualities of the soil and properties of a given tree influence each other. We implement survival analysis to identify the most important variables and use a variety of statistical learning models to compare and contrast the accuracy of each method. We present a report that analyzes how the cox proportional hazards regression model (coxph), random forest, survival trees, and support vector machines (SVM) compare to each other in their ability to understand the plant-soil relationships. 

The dataset in this study (https://www.kaggle.com/datasets/yekenot/tree-survival-prediction/data), which is hosted on Kaggle, was added by the authors of the recent journal article "Tree seedling functional traits mediate plant-soil feedback survival responses across a gradient of light availability" (Wood et al. 2023) (https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0293906#sec002). In the article, the authors conduct a field experiment in Michigan with four tree species planted in seven soil sources (sterilized conspecific, live conspecific, and five heterospecific) and under a gradient of forest understory light levels (low, medium, and high). As the variables used in this dataset are often biological terms, we explain some below.

### Study design

The reason why we are applying survival analysis to this dataset is because Wood et al. (2023) write about seedling survival. The authors indicate that they planted trees in field plots in May and June 2018, after which point they observed survival twice a week throughout the next 16 weeks of the growing season (see Figs. 1-3 below for details on dates on which the seedlings were planted). Each period in which they observed the seedlings is labelled a "*census*". Three weeks into the study period, the authors "harvested" certain seedlings to obtain values for variables such as the concentrations of chemical compounds and mycorrhizal fungi, which will be discussed more below. The authors strongly imply that they did not replant these harvested seedlings, for they call the process of measurement "destructive". After the 16-week period, Wood and colleagues analyzed survival with the `coxph` function in R, much as we did in class. The specific code is not included in the paper or the dataset manuscript, but we will also use this function for the sake of comparison and reproducibility.

```{r, warning = F, message = F}
# Convert to date obaject (Batra et al, 202) https://epirhandbook.com/en/working-with-dates.html
tree_EDA3 <- trees %>% 
  mutate(PlantDate = mdy(PlantDate)) %>% 
  mutate(PlantDateYear = year(PlantDate),
         PlantDateMonth = month(PlantDate),
         PlantDateDay = day(PlantDate))

ggplot(data = tree_EDA3,mapping = aes(x = factor(PlantDateYear))) + 
  geom_bar()+
  labs(title = "Figure 1. Year of Plant Date",
       subtitle = "Faceted by species",
       x = "Year", y =  "Count")+
  facet_grid(. ~ Species)

tree_EDA3 <- tree_EDA3 %>%
  mutate(PlantDateMonth = case_when(PlantDateMonth == 5 ~ "May",
                                    PlantDateMonth == 6 ~ "June")) %>%
  mutate(PlantDateMonth = factor(PlantDateMonth, 
                            levels = c("May", "June")))
ggplot(data = tree_EDA3,mapping = aes(x = PlantDateMonth)) + 
  geom_bar()+
  labs(title = "Figure 2. Month of Plant Date",
       subtitle = "Faceted by species",
       x = "Month", y =  "Count")+
  facet_grid(. ~ Species)

ggplot(data = tree_EDA3,mapping = aes(x = PlantDateDay)) + 
  geom_histogram()+
  labs(title = "Figure 3. Day of Plant Date",
       subtitle = "Faceted by species",
       x = "Day", y =  "Count")+
  facet_grid(. ~ Species)
```

### Study focus

Wood and colleagues specifically seek to investigate the linkages between plant-soil feedbacks (PSFs) and functional traits in the seedlings which they planted. The former term refers to the idea of plants exacting a sort of change in the soil in which they grow via relationships with mycorrhizal fungi -- fungi which interact with plant roots and can exchange nutrients -- or microbial pathogens. A positive PSF is defined as a feedback loop which benefits seedlings of a given species when they are grown in soil which already hosts a plant of the same species. This soil is also called *conspecific* soil. By the same token, a negative PSF is seen when seedlings of a given species grow better in soil in which trees of another species are growing -- this is called *heterospecific* soil (Wood et al. 2023).

Fig. 4 shows the distribution of the soil sources segmented by tree species. Note that in the dataset, if a conspecific soil was sterilized, then it was called *sterilized*. In Fig. 4, within each type of soil source, tree species are nearly evenly distributed. However, it also indicates that Heterospecific soil was more common than Conspecific or Sterilized. 

```{r}
# change the order of levels in Conspecific to make the plot easier to understand
tree_EDA <- trees %>%
  mutate(Conspecific = factor(Conspecific,
                              levels = c("Conspecific",
                                         "Sterilized",
                                         "Heterospecific")))

ggplot(data = tree_EDA, mapping = aes(x = Conspecific, fill = Species)) + 
  geom_bar() +
  labs(y = "Count", x = "Soil source",
       title = "Figure 4. Soil sources",
       subtitle = "Segmented by species")
```


### Functional traits

The researchers cite previous literature which investigates the idea of functional traits -- characteristics of a tree which could have an impact on its growth -- interfacing with PSFs. The main traits they introduce are *phenolics*, *lignin*, and nonstructural carbohydrates (*NSC*s), but they do not go into much detail on the context of these terms. Phenolics are an example of a secondary metabolite, a class of chemical which is not found in all plant cells but which can sometimes be produced in response to herbivory. A group of phenolics which has this function is the tannins, which provide a bitter taste as a deterrent to herbivores which consume the leaves (Evert and Eichhorn 2013). Lignin is in fact another type of phenolic, but it is instead known for its provision of structure to the cell walls of plant cells (Evert and Eichhorn 2013). Last, NSCs are carbohydrates such as sugars and starch (Zhang et al. 2022) which can support the plant in times of drought (Tomasella et al. 2019) and can help respond to damage in plant parts (Dietze et al. 2014). Wood and colleagues state that these traits could be considered defensive characteristics against the threat of pathogens (Wood et al. 2023).

### AMF and EMF

The researchers also include that the percentage of the root of a tree which has been "colonized" by mycorrhizal fungi could be considered a defensive trait (Wood et al. 2023). Mycorrhizal fungi are split into arbuscular mycorrhizal fungi (*AMF*) and ectomycorrhizal fungi (*EMF*). The former, also referred to as endomycorrhizal, are fungi which form associations with plants by entering root cells and growing inside of them. The latter are fungi which instead grow around roots (Evert and Eichhorn 2013). Wood and colleagues hold that a tree which has a higher AMF or EMF percentage may be afforded greater protection against pathogens. 
We noticed that many % EMF values, which is one of the variables in the dataset, had been recorded as NA. We contacted Dr. Wood, who stated that tree species in the study which associated with AMF do not historically associate with EMF, so she did not even measure % EMF in these trees. For this reason, she stated that the NAs could be replaced with 0s as a form of imputation (Dr. Katherine Wood, personal communication, 12/11/2023). We opted to make this change to the data below to have our analyses include much more data. This observation of the researchers is consistent with Mushinski et al. (2020), who state that many tree species in the Eastern U.S. only associate with one of these types of fungi. 

### Tree species

The list of tree species used in the study is as follows:
- Sugar maple (*Acer saccharum*)
- Black cherry (*Prunus serotina*)
- White oak (*Quercus alba*)
- Northern red oak (*Quercus rubra*)

As Fig. 5 below shows, the number of seedlings for each of the four species is in a similar range.

```{r}
ggplot(data = trees, mapping = aes(x = Species)) + 
  geom_bar(fill = "lightblue") +
  labs(y = "Count", x = "Tree species",
       title = "Figure 5. Number of trees",
       subtitle = "Segmented by species")
```

### Light availability 

Lastly, in addition to soil sources (Conspecific, Sterilized, or Heterospecific), light availability was another controlled condition in the field experiment by Wood et al (2023). Light availability was initially measured as a continuous variable by using Indirect Site Factor (ISF) which is the proportion of solar radiation at a given location relative to an open site (Wood et. al, 2023). Then, the range of the ISF value was split into three partitions of equal length to create three light levels (low, medium, and high). Fig. 6 below is a distribution of those three light levels segmented by species. Within each light availability, the number of the seedlings is around the same for all the four species. Yet, more seedlings had the low or medium light level than high. 

```{r}
# change levels of Light_Cat (Posit Community, 2018)
tree_EDA2 <- trees %>% 
  mutate(Light_Cat = case_when(Light_Cat == "Med" ~ "Medium",
                               Light_Cat == "High" ~ "High",
                               Light_Cat == "Low" ~ "Low")) %>%
  mutate(Light_Cat = factor(Light_Cat, 
                            levels = c("Low", "Medium", "High")))

ggplot(data = tree_EDA2, 
       mapping = aes(x = Light_Cat, fill = Species)) +
geom_bar() + 
labs(y = "Count", x = "Light level",
     title = "Figure 6. Light levels",
     subtitle = "Segmented by species")
```



## 2. Ai: Methods 

Before building statistical models for predicting tree survival, we conducted hierarchical clustering to identify any outliers. We then used Principal Component Analysis (PCA) because there were ten numerical variables that could influence tree survival and using PCA would reduce the dimension to a smaller number of variables that still summarized most of the variability in those variables. Following PCA, we built a random forest model based on loading scores for the principal components to answer one of our research questions, which was to compare the accuracy of predictive algorithms for tree survival. 

Although using principal components for random forest is certainly one way of building a predictive model for tree survival, it has limitations. One limitation is that we can only determine variable importance in terms of principal components and not in terms of variables in the original dataset. Another limitation is that we can only use numerical variables for PCA. Given that one of our research questions was to understand what variables in the data were more influential than others, these limitations had to be avoided. Hence, we built a Cox proportional hazards regression model (Coxph), a support vector machine (SVM) model, and a random forest model by using all the variables (both numerical and categorical) that could influence tree survival. 

## 3. Ellie: Metrics

In this study, we use the Harrel’s concordance index (c-index) to evaluate the quality of our statistical learning models. This survival metric is used to quantify how well the predicted risk score correlates with the survival time. In particular, the c-index prediction error is determined by 1-C, where C is the c-index. This metric takes on a value between 0 and 1 and quantifies how well the model accurately ranks two random observations in terms of survival. Namely, a c-index of 0.5 is no better than random guessing and a c-index of 0 is evidence of a perfect model. Mathematically, the c-index is defined as 

$ C = \frac{\sum_{i,i':y_i>y_i'}I(\hat{n_{i'}}>\hat{n_{i}})\delta_{i'}}{\sum_{i,i':y_i>y_i'}\delta_{i'}}$,

where $I$ represents the indicator variable, $\hat{n_{i'}}$ and $\hat{n_{i'}}$ represent a pair of observations, and $\delta_{i'}$ is the status variable, taking on a 0 value if the $i'^{th}$ variable is censored and 1 if the $i'^{th}$ variable is uncensored. The indicator variable $I$ similarly takes on a binary value of either 0 or 1, where $I = 1$ if $\hat{n_{i'}}>\hat{n_{i'}}$ (the hazard for the $i'^{th}$ observation is larger than the $i^{th}$ observation) and $I = 0$ otherwise. Practically, this means that the c-index will take on a larger value when it correctly predicts that $\hat{n_{i'}}>\hat{n_{i'}}$, resulting in an error ($1-C$) close to 0. 

As a result, this metric appropriate for defining the efficacy of our model in predicting survival amongst trees. 

## 4. Results

### Ai: 4.1 Hierarchical clustering 

Below, we conducted hierarchical clustering for numerical variables. Among the numerical variables, we did not include the variable No because it was an ID number unique to each tree.

```{r, warning = F}
# convert PlantDate in character format to date time object
tree_hc <- trees %>% 
  mutate(PlantDate = mdy(PlantDate)) %>% # change to standard format(Year-Month-Day)
  mutate(PlantDateYear = year(PlantDate),
          PlantDateMonth = month(PlantDate),
          PlantDateDay = day(PlantDate))

# scale tree data without the variable Census
tree_scaled <- select_if(tree_hc, is.numeric) %>% # select only numeric columns
                select(-No) 
               
# calculate all pairwise distances
tree_distances <- dist(tree_scaled)

# Do hierarchical clustering
hc <- tree_distances %>%
  hclust() %>%
  as.dendrogram() %>%
  place_labels(trees$No) 

plot(hc,
     xlab = "Tree ID",
     ylab = "Height") 
title('Figure 7. Cluster dendrogram')
```

As shown in the dendrogram in Fig. 7, there was no split with only one terminal node, which led us to conclude that there was no outlier to be removed for data analysis. 

### Ai: 4.2 Principal Component Analysis (PCA)

In this section, we first calculate principal components of numerical variables that may have impacted the survival of seedlings and then use loading scores for the principal components to build a random forest model.

Because PCA only works with numerical variables, we first removed the categorical variables shown below. 

* Species: Names of tree species

* Light Cat: Categorical variable for light levels (Low, Medium, High)

* Soil: Species from which the soil core was taken 

* Adult: Individual tree that soil was taken from

* Sterile: Whether the soil was sterilized or not

* Conspecific: Whether the soil was conspecific, heterospecific, or sterilized conspecific

* Myco: Mycorrhizal type of the seedling species (AMF or EMF)

* SoilMyco: Mycorrhizal type of the species culturing the soil (AMF or EMF)

* Event: Status of each seedling at a given time; 0 for alive and 1 for dead

Additionally, we removed five numerical variables for the following reasons. 

* No: This was a unique ID attached to each seedling, so it should not have influenced tree survival. 

* Harvest, Alive: the variables Harvest and Alive were related to what happened to seedlings after the end of the experiment, so we assumed that they would not have impacted tree survival.

* Time: This was the status of each seedling at a given time and hence should not have influenced tree survival. 

* Census: This was the number of week that a given tree died or the experiment ended (whichever was earlier); it indicated essentially the same thing as the variable Time. Thus, we removed it as well.

* PlantDateYear: Because every observation had 2018 as PlantDateYear (see Fig. 4), this variable should not have influenced tree survival.

In short, we calculated loading scores by using the following variables. 

* Plot: Number of the field plot the seedling was planted in (1-18)

* Subplot: Subplot within the main plot the seedling was planted in (A-E)

* PlantDateDay: Day of date when the seedling was planted

* PlantDateMonth: Month of date when the seedling was planted

* Light ISF: Amount of light reaching each subplot at a height of 1m

* Core: Year the soil core was removed from the field

* AMF: Percent arbuscular mycorrhizal fungi colonization on the fine roots of harvested seedlings

* EMF: Percent ectomycorrhizal fungi colonization on the root tips of harvested seedlings

* Phenolics: nmol Gallic acid equivalents per mg dry extract

* NSC: percent dry mass nonstructural carbohydrates

* Lignin: percent dry mass lignin

#### Find loading score 
```{r}
# Convert all NA EMF values to 0 (stackoverflow, 2011) (https://stackoverflow.com/questions/8161836/how-do-i-replace-na-values-with-zeros-in-an-r-dataframe)
tree_pca <- trees %>%
    mutate(EMF = if_else(is.na(EMF), 0, EMF))


# convert PlantDate in character format to date time object
tree_pca <- tree_pca %>%
  mutate(PlantDate = mdy(PlantDate)) %>% # change to date object (Year-Month-Day)
  mutate(PlantDateYear = year(PlantDate),
         PlantDateMonth = month(PlantDate),
         PlantDateDay = day(PlantDate))  %>%
  select(-PlantDate, -PlantDateYear) # remove the original PlantDate and PlantDateYear

# select necessary variables
tree_pca <- tree_pca %>%
  select(-c(No, Harvest, Alive, Census)) %>%
  select_if(is.numeric) %>%
  na.omit()

# scale data and conduct PCA
pca1 <- prcomp(tree_pca %>% select(-c(Event, Time)), scale = TRUE) # remove what we predict (Event and Time)
```

#### Ai: Random forest using PCA

After finding loading scores for the principal components, we used them to build a random forest model that predicted the survival object of the variables Time and Event (a detailed discussion on the survival object is in Section 4.3). We chose random forest as our supervised learning technique because we did not know which loading score(s) had the highest importance in predicting the survival object.  

```{r}
# Create a vector of loading scores from all the PCs
loading_score_vec <- pca1$x

# Create a dataset of loading scores, Event, and Time
tree_subset <- data.frame(loading_score_vec) %>%
  mutate(Event = tree_pca$Event,
         Time = tree_pca$Time) 

# Build a random forest model 
rf_test<- ranger(Surv(Time, Event) ~., 
             data = tree_subset,
             importance = 'impurity')
rf_test
```

In the above result, the Harrel’s concordance index (c-index) for this random forest model based on loading scores for the principal components is approximately 0.699. This means that, given two random seedlings from the dataset, the model can predict survival with 69.9% accuracy. 


### Andy: 4.3 Survival function and Coxph

Besides random forest with PC loading scores, the Cox proportional (Coxph) hazards model is another way to predict the survival object of the time and event variables. This section first explores the use of the `Surv` function and then builds a Coxph model for survival analysis.

```{r Data preparation}

# Remove unwanted variables
tree <- trees %>% select(-No, -Harvest, -Alive, -Adult)

# Convert all NA EMF values to 0 with researchers' blessing
tree$EMF[is.na(tree$EMF)] <- 0

# Check for remaining NA values
str_which(tree$EMF, "NA")

# convert PlantDate in character format to date time object
tree <- tree %>% 
  mutate(PlantDate = mdy(PlantDate)) %>% # change to standard format(Year-Month-Day)
  mutate(PlantDateYear = year(PlantDate),
          PlantDateMonth = month(PlantDate),
          PlantDateDay = day(PlantDate)) %>%
  select(-PlantDate)

# Factor variables
tree <- tree %>%
  mutate(Species = factor(Species)) %>%
  mutate(Soil = factor(Soil)) %>%
  mutate(Conspecific = factor(Conspecific)) %>%
  mutate(Subplot = factor(Subplot)) %>%
  mutate(Light_Cat = factor(Light_Cat)) %>%
  mutate(Sterile = factor(Sterile)) %>%
  mutate(Myco = factor(Myco)) %>%
  mutate(SoilMyco = factor(SoilMyco))
  
# Create a survival object
tree_surv <- Surv(time=tree$Time, event=tree$Event)
```

The survival object can first be used in the `survfit` function. We first implemented this function in class with no covariates, which was indicated with a `1` in the formula term reserved for predictors. The resulting survival curve shows an extremely slight decrease in estimated probability of survival at about 15 days and a sharp decrease at about 25 days. Quick exploration of relevant variables can be achieved via Kaggle by looking at the variable histograms and dataset columns which are embedded on the page. Indeed, just 3 observations carry time values of 14, and all of these seedlings seem to have died based on their event value of 1. Many more trees have a time value of 24.5 days, corresponding to a census value of 7. There are no census values less than 4, which signifies that the researchers did not harvest nor note the death of any seedling prior to 14 days into the growing season.

Using the rationale that decreases in survival probability relate to censuses when the researchers assessed the mortality of trees and harvested certain individuals, other periods of heightened risk include 42 days (census 12), 45 days (census 13). By this stage of the growing season, probability of survival has decreased to approximately 60%. The probability decreases to approximately 30% before leveling out for the final 40-odd days of the growing season. Due to the fact that seedling survival was not observed each day, it is not likely that all trees which were noted to have died at census 13 died on day 45; some may have died on days 43 and 44. That is the nature of the data, however, and it was noted in class that survival curves take on a stepwise shape.

In general, this curve indicates that survival is not likely to be compromised at the very start of the growing season and that surviving plants enjoy a risk-deficient period of time about 80 days into the growing season where mortality is relatively unlikely. The most risky periods for the study trees are found from approximately 20 to 45 days into the season; probability of survival decreases by about 40% in this period and 30% in the following 35 days. 

```{r Survival curve}
# Survival curve with no covariates
surv_fit_tree_base <- survfit(tree_surv~1)

# Survival curve
plot(surv_fit_tree_base)
```

We can also try fitting covariates to the survival curve. This can be simpler to do by creating the survival object inside of the survfit function rather than passing in an existing object. One covariate that makes sense to add is the species of the tree, given that the researchers display survival curves for each of the four species in the paper (Figure 2). We can diverge from the method used in class by using the `ggsurvplot` function of the `survminer` package. 

It is abundantly clear from the resulting graph that different species have radically different survival curves. In particular, both oak species (Quercus rubra is red oak and Q. alba is white oak) are essentially always more likely to survive than black cherry (Prunus serotina) or sugar maple (Acer saccharum) seedlings. The latter two species have broadly similar curves which decrease to near-zero survival probability at approximately 70 days. The oak species, however, do not appear to see their survival probabilities fall below approximately 60% at any point in the late growing season. The shapes of all curves do indeed compare favorably to Figure 2 in the original study, which is a positive sign for this visualization. We can discuss why the curves are so different later in the report.

```{r Covariate survival curve}
# Survival curve with species as covariate
surv_fit_tree_species <- survfit(Surv(Time, Event) ~ Species,
                               data = tree)

# Alphabetical order: Acer saccharum, Prunus serotina, Quercus alba, Quercus rubra
surv_fit_tree_species$n

# Use survminer to visualize plot
ggsurvplot(surv_fit_tree_species, data=tree)
```

The Cox proportional hazards model is also possible to implement using a survival object. We are choosing to build up a `coxph` model by inputting one variable at a time to see if the variable is important. Importance of variables can be judged by observing whether the p-value for the variable (or any of its factors if it is a character variable) is significant (≤0.05). All variables currently in the model have at least one significant p-value, in the case of chr variables. 

Relevant chr variables include Species, Soil, and SoilMyco. The factors which are displayed for the object are being compared to the baseline factor, which is the level not shown in the output. The baseline is the first factor when the list of factors is sorted alphabetically. 

As an example of interpreting factors, the factor of the variable Species which pertains to northern red oak (*Q. rubra*) individuals is significant when compared to the baseline of sugar maple (*A. saccharum*) individuals (the only species which is missing from the `coxph` function output; p < 0.02). The negative coefficient suggests that the hazard for this factor is decreased compared to the baseline. When we look at `survminer` plot above, this outcome makes sense; northern red oak had a survival curve which nearly always had higher survival probability values when compared to the curve for sugar maple. 

Other significant results include:
- For the "EMF" factor of the variable "SoilMyco", proportional hazard is higher when compared to the baseline factor of "AMF".
- For the sugar maple (A. saccharum) factor of the variable "Soil", proportional hazard is higher compared to the baseline factor of *Acer rubrum* (red maple). No red maple seedlings were actually planted, but any seedlings grown in soil from soil cores which were collected beneath red maple trees are part of this factor. 

Relevant numerical variables include Plot, EMF, Phenolics, PlantDateMonth, and PlantDateDay. For numerical variables, significance indicates that a one-unit increase in value changes hazard according to the value and direction of the coefficient. 

Significant results include:
- A one-unit increase in the value of the "Plot" variable increases hazard by a very slight margin. This may not be deemed to be very important due to the magnitude of the coefficient. Notwithstanding, we may surmise that this variable should ideally be insignificant for experimental design.
- A one-unit increase in the value of the "EMF" variable decreases hazard by a small amount.
- A one-unit increase in the value of the "Phenolics" variable also decreases hazard, but it does so by a larger amount. The coefficient can be interpreted with the idea that a seedling with a value of phenolics one unit higher than another seedling seems to have only 67% of the risk.
- A one day increase in planting date increases hazard very slightly, and a one month increase in planting date increases hazard to a much greater degree than all other significant results here. This is slightly confusing given the methods section of the article, which implies that all planting occurred in June 2018. The distribution of values for the variable, however, makes clear that there are many seedlings which were planted in May 2018. The Cox model result here could therefore be suggesting that seedlings planted in June had a higher risk of death than those planted in May.

```{r Coxph}
# Coxph
coxph_tree <- coxph(Surv(Time, Event) ~ Species + SoilMyco + Sterile + Soil + EMF + Phenolics + PlantDateMonth +
                      PlantDateDay + Plot, data=tree)

coxph_tree
```

## 4.4 Andy: SVM with survival object

We have used support vector machines for datasets with many possible predictor variables. It thus seems prudent to try to use SVM for this problem. Upon testing SVM with the `caret` package, which we have done before in class using a value of "svmLinear2" for the `method` argument, the `train` function does not seem to be able to work. This is likely because we have passed in a survival object as `x` instead of the typical single predictor, for the error is "Invalid operation on a survival time". Altering the method to one of the other SVM methods included as options in caret also does not work, and the `e1071` package itself predictably fails as well. 

```{r SVM, eval = FALSE}
# Caret package does not support survival models
#svm_tree <- train(Surv(Time, Event)~., data=tree %>% na.omit(), method="svmLinear2")

# e1071 package also throws an error
#svm_tree <- svm(Surv(Time, Event)~.-PlantDateYear, data=tree)

# Other caret methods testing
svm_tree <- train(Surv(Time, Event)~.-PlantDateYear, data=tree %>% na.omit(), method="svmPoly")
svm_tree <- train(Surv(Time, Event)~.-PlantDateYear, data=tree %>% na.omit(), method="lssvmRadial")
svm_tree <- train(Surv(Time, Event)~.-PlantDateYear, data=tree %>% na.omit(), method="lssvmPoly")
svm_tree <- train(Surv(Time, Event)~.-PlantDateYear, data=tree %>% na.omit(), method="svmLinear3")
svm_tree <- train(Surv(Time, Event)~.-PlantDateYear, data=tree %>% na.omit(), method="svmBoundrangeString")
```

We can instead use the `survivalsvm` package to predict survival time and receive a concordance index value to compare with other models. When predicting using a training subset and a testing subset, the C-index value for survivalsvm is quite high at approximately 0.97. Unfortunately, the `varImp` function cannot be applied to this model, as we are not using the caret package. A [paper](https://journal.r-project.org/archive/2018/RJ-2018-005/RJ-2018-005.pdf) describing the package also does not contain a mention of variable importance.

```{r survivalSVM}
set.seed(1)

# Split data
train_rows <- sample(1:nrow(tree), size=nrow(tree)/2)

# Create train and test subsets
train <- tree[train_rows,]
test <- tree[-train_rows,]

# survivalsvm function
svm_tree <- survivalsvm(Surv(Time, Event)~.-Census, data=train, type="vanbelle1", diff.meth="makediff1", gamma.mu=1)

# predictions using the resulting object
svm_pred <- predict(svm_tree, newdata=test)

# get c-index value
svm_c <- conindex(svm_pred, test$Time)

svm_c
```

## 4.5 Ellie: Single Survival Tree
```{r}
## REMOVE THIS CHUNK LATER
#tree <- read.csv("Tree_Data.csv") 
tree <- trees

# Remove unwanted variables
tree_clean <- tree %>% select(-No, -Harvest, -Alive, -Adult)

# Convert all NA EMF values to 0 with researchers' blessing
tree_clean$EMF[is.na(tree$EMF)] <- 0

# Check for remaining NA values
str_which(tree_clean$EMF, "NA")

# convert PlantDate in character format to date time object
tree_clean <- tree_clean %>% 
  mutate(PlantDate = as.Date(PlantDate)) %>%
  mutate(PlantDateDay = day(PlantDate)) %>%
  mutate(PlantDateMonth = month(PlantDate)) %>%
  select(-PlantDate)
  # change to standard format(Year-Month-Day)


# Factor variables
tree_clean <- tree_clean %>%
  mutate(Species = factor(Species)) %>%
  mutate(Soil = factor(Soil)) %>%
  mutate(Conspecific = factor(Conspecific)) %>%
  mutate(Subplot = factor(Subplot)) %>%
  mutate(Light_Cat = factor(Light_Cat)) %>%
  mutate(Sterile = factor(Sterile)) %>%
  mutate(Myco = factor(Myco)) %>%
  mutate(SoilMyco = factor(SoilMyco))

#table(tree_clean$PlantDate)
```


A survival tree to analyze the relationships between variables in the dataset can be implemented by analyzing splits in the data that yield the largest differences in survival. This can be done by comparing the survival outcomes of different categories in a given variable and determining which traits yield the highest chance of survival.

As with our SVM model, we pass in a survival object into our model for the model to make survival predictions. The results of the predictions made from the tree are shown in 
```{r}
surv_tree <- rpart(Surv(Time, Event) ~.-Census, data = tree_clean, control = rpart.control(cp = 0.005), model = TRUE)
rpart.plot(surv_tree, main = "Fig. 5: Single Decision Tree Example")
validate(surv_tree)
```


Fig. 5 highlights an example of a single decision tree to model the tree survival data. It is apparent from this figure that phenolics, the type of soil, and plant date all play a significant role when the algorithm determines the splits within the data that yield the largest changes in survival. With use of the "validate" function in the rms package, different control values $k$ were tested and the appropriate $D_{xy}$ values for training and testing were output. The package implements 10-fold cross validation to ensure that the error values accurately represent how well the algorithm might perform on new data. For each attempted $k$, the mean $D_{xy}$ was calculated. One can convert from $D_{xy}$ to the c-index through the relationship
$D_{xy} = 2(C-0.5)$, 
where $C$ is the c-index. 

```{r}
tree_res <- validate(surv_tree)
best_c <- max(tree_res$dxy.val)
# Calculate c-index from testing dxy 
c_ind <- 0.5 + best_c/2
c_ind
1-c_ind
```

As shown above, the c-index is ~0.74, which means that the associated error is 0.26. This result implicates that the model is performing better than random guessing and specifically can predict with 74% accuracy how long it will take for a tree to die given the reported conditions. This method, however, is susceptible to high variance. Because this model is a single decision tree, there is a lot of uncertainty and a few changes in some of the edge observations could change the way that the model is predicting in a significant manner. This tree might be predicting with 74% survival accuracy in this set of observations, but might perform much differently given a slightly different set of observations. 

```{r}
surv_tree$variable.importance
```

Specifically, we can view and analyze how important each variable in the dataset is in determining tree survival. It is apparent from the above importance analysis that phenolics, tree species, lignin, the day that the tree was planted, myco, and EMF are the most important factors in this prediction. 

## 4.6 Random Survival Forest

A similar model with less variance is the random forest. This model makes use of a collection of "weak-learners" to make predictions on a dataset. These weak-learners are designed to make predictions that are slightly better than random guessing and a majority vote is taken to determine the resulting prediction for a given observation. Because this method uses majority vote, it is subject to less variance than a single tree model. A similar approach can be done for survival analysis on a random forest. Note: 1 observation was omitted, as the reported "event" was unknown. In a similar way as done for the single tree, a survival object is passed into the ranger function and importance is tracked. 
```{r}
rf <- ranger(Surv(Time, Event) ~.-Census, data = tree_clean %>%na.omit(), importance = 'impurity')
rf$prediction.error
rf_c = 1 - rf$prediction.error
rf_c
as.data.frame(rf$variable.importance) %>%
  arrange(-rf$variable.importance)
```
As shown above, the random forest makes survival predictions that yield a c-index of $0.70$. This result implicates that the tree is predicting survival times with $70%$ accuracy (and $30%$ error). This is a worse prediction than the one found above for a single decision tree, however, it is important to reiterate that this model is subject to less bias than the single decision tree and might prove to generalize better to new data. 

Similarly, an importance analysis can be performed on the random forest model. Specifically, it can be seen that lignin and phenolics are once again amongst the most important variables, as well as AMF, NSC, and the plot that the tree was planted in. It is clear from these tree-based analyses that the lignin and the phenolics of a given tree are the most indicative of tree survival. This behavior makes sense because lignin and phenolics serve as chemical and physical defense against soil-borne microbes (Wood et. al, 2023). 

### Interpreting these results

With the information that lignin and phenolics are important variables for tree survival, we now analyze what role these variables have in tree survival. In other words, what quantities of lignin and phenolics influence survival in trees? 

To understand the distribution of these variables, the distribution of lignin and phenolics across the dataset were plotted. 
```{r}
histogram(tree_clean$Lignin,
          xlab = "Lignin (%)",
          ylab = "Percent of Total Dataset",
          main = "Fig. 6: Distribution of Lignin content across the dataset.")
```
```{r}
histogram(tree_clean$Phenolics,
          xlab = "Phenolcics (nmol/mg)",
          ylab = "Percent of Total Dataset",
          main = "Fig 7: Distribution of Phenolics content across the dataset.")
```
The above histograms (Fig. 6 and Fig. 7) portray the dataset's distribution of lignin and phenolics content across trees in the dataset. Both appear to have two groupings with higher and lower content in each of the two variables. 

To analyze the relationship between lignin and phenolics content and tree survival, we have grouped the lignin and phenolics content into three groups for analysis, high, mid, and low content. 
```{r}

lignin1 <- tree_clean%>%
  mutate(Lignin= case_when(Lignin>20 ~ "high",
                            Lignin>10 ~ "mid",
                            Lignin<10 ~ "low"))
fit <- survfit(Surv(Time, Event) ~Lignin, data = lignin1)


ggsurvplot(fit,
           xlab = "Time",
           title = "Fig. 8: Survival Probability for varying lignin 
           content")
```

Fig. 8 demonstrates that trees possessing more lignin is indicative of higher survival probability. This conclusion makes sense because more lignin is indicative of higher chemical defense. 

A similar analysis can be conducted for phenolics. 
```{r}
pheno <- tree_clean%>%
  mutate(Phenolics= case_when(Phenolics>3 ~ "high",
                            Phenolics>0 ~ "mid",
                            Phenolics<0 ~ "low"))
p_fit <- survfit(Surv(Time, Event) ~Phenolics, data = pheno)


ggsurvplot(p_fit,
            xlab = "Time",
           title = "Fig. 9: Survival Probability for varying phenolics 
           content")
```

Fig. 9 demonstrates that trees that possess more phenolics have a notably higher chance of survival. This conclusion also makes sense because higher phenolics content is indicative of higher physical defense against soil microbes. 

# Conclusion

From the above results, we have demonstrated the various qualities that affect tree survival. It has been demonstrated from our survival fit methods that tree species is an important factor for tree survival, as different species contain different survival characteristics. In particular cherry and maple seedlings are generally at higher risk of death than their oak counterparts. It was also found in several statistical learning methods that larger presence of phenolics is indicative of higher overall survival probability. As found in our tree-based statistical learning methods, the presence of high of physical defense (phenolics) and chemical defense (lignin) are indicative of higher survival probability and thus decreased hazard over time. Overall, we found the survivalsvm model to have the highest C-index, which indicates that it may be the best model with respect to predictions of survival. However, we also note that tree-based methods helpfully allowed us to see variable importance, which is quite relevant for any report which seeks to identify which of the many variables in the dataset contribute meaningfully to a model.